{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xASeDIoSKcpm",
        "outputId": "56297637-9ca8-4625-9e79-5ebd29ed4ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1R56ItVgKcpn"
      },
      "outputs": [],
      "source": [
        "# Zuha Umar\n",
        "# 20I-0603\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "train_file_path = \"/content/drive/My Drive/train.csv\"\n",
        "test_file_path = \"/content/drive/My Drive/test.csv\"\n",
        "test_labels_file_path = \"/content/drive/My Drive/test_label.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBBO3nInKyZn",
        "outputId": "8ee38b9c-5ebd-4d31-ba17-855ee91d5fd3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNVxzfNhKcpn",
        "outputId": "6f84a1f4-b131-4dbf-c256-6019372e58c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['timestamp_(min)', 'feature_0', 'feature_1', 'feature_2', 'feature_3',\n",
            "       'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8',\n",
            "       'feature_9', 'feature_10', 'feature_11', 'feature_12', 'feature_13',\n",
            "       'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18',\n",
            "       'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23',\n",
            "       'feature_24'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "df_train = pd.read_csv(train_file_path)\n",
        "print(df_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "E8hZzZScKcpn",
        "outputId": "ef375e82-a132-4c93-dd4a-1ae54ea286d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   timestamp_(min)  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
              "0              0.0   0.732689   0.761748   0.606848   0.488746   0.424310   \n",
              "1              1.0   0.732799   0.761855   0.607133   0.488781   0.432008   \n",
              "2              2.0   0.732938   0.761594   0.606895   0.488791   0.418858   \n",
              "3              3.0   0.732893   0.761656   0.606478   0.488802   0.417896   \n",
              "4              4.0   0.732788   0.761573   0.606777   0.488800   0.421103   \n",
              "5              5.0   0.732654   0.761304   0.607815   0.488751   0.403143   \n",
              "6              6.0   0.732544   0.761418   0.607595   0.488748   0.425914   \n",
              "7              7.0   0.732575   0.761475   0.608642   0.488771   0.428480   \n",
              "8              8.0   0.732440   0.761603   0.608882   0.488807   0.427518   \n",
              "9              9.0   0.732574   0.761135   0.609090   0.488796   0.418217   \n",
              "\n",
              "   feature_5  feature_6  feature_7  feature_8  ...  feature_15  feature_16  \\\n",
              "0   0.403609   0.519318   0.398792   0.451453  ...    0.318797    0.451856   \n",
              "1   0.410256   0.511364   0.402568   0.455657  ...    0.321463    0.456123   \n",
              "2   0.407724   0.488636   0.396526   0.456104  ...    0.347219    0.456692   \n",
              "3   0.404242   0.500000   0.405589   0.460020  ...    0.361904    0.460532   \n",
              "4   0.407407   0.511364   0.399547   0.458507  ...    0.359767    0.458825   \n",
              "5   0.402026   0.528409   0.383686   0.449682  ...    0.357345    0.450149   \n",
              "6   0.408357   0.528409   0.419562   0.453380  ...    0.364608    0.453705   \n",
              "7   0.415321   0.534091   0.411254   0.464791  ...    0.307913    0.465083   \n",
              "8   0.410890   0.517045   0.407100   0.464057  ...    0.309998    0.464514   \n",
              "9   0.414688   0.528409   0.402190   0.457764  ...    0.318445    0.458256   \n",
              "\n",
              "   feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
              "0    0.571500    0.469717    0.609883    0.008432    0.000000    0.481838   \n",
              "1    0.562226    0.466533    0.629812    0.008432    0.000000    0.477218   \n",
              "2    0.572002    0.487845    0.643598    0.006745    0.000000    0.492623   \n",
              "3    0.563354    0.479512    0.644690    0.008432    0.000000    0.457064   \n",
              "4    0.563354    0.448298    0.629948    0.006745    0.000000    0.472223   \n",
              "5    0.577767    0.462758    0.626945    0.006745    0.000000    0.475962   \n",
              "6    0.566612    0.475290    0.629402    0.006745    0.003559    0.487324   \n",
              "7    0.567239    0.488204    0.631313    0.008432    0.003559    0.473797   \n",
              "8    0.576889    0.493189    0.636364    0.008432    0.000000    0.481318   \n",
              "9    0.574759    0.502262    0.627628    0.008432    0.000000    0.483109   \n",
              "\n",
              "   feature_23  feature_24  \n",
              "0    0.006536    0.138249  \n",
              "1    0.006536    0.115207  \n",
              "2    0.008715    0.092166  \n",
              "3    0.008715    0.142857  \n",
              "4    0.006536    0.170507  \n",
              "5    0.013072    0.138249  \n",
              "6    0.008715    0.129032  \n",
              "7    0.010893    0.142857  \n",
              "8    0.008715    0.147465  \n",
              "9    0.006536    0.124424  \n",
              "\n",
              "[10 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e9821dd-fca2-4ae4-8a55-01bc6e1a2473\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp_(min)</th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>feature_20</th>\n",
              "      <th>feature_21</th>\n",
              "      <th>feature_22</th>\n",
              "      <th>feature_23</th>\n",
              "      <th>feature_24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.732689</td>\n",
              "      <td>0.761748</td>\n",
              "      <td>0.606848</td>\n",
              "      <td>0.488746</td>\n",
              "      <td>0.424310</td>\n",
              "      <td>0.403609</td>\n",
              "      <td>0.519318</td>\n",
              "      <td>0.398792</td>\n",
              "      <td>0.451453</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318797</td>\n",
              "      <td>0.451856</td>\n",
              "      <td>0.571500</td>\n",
              "      <td>0.469717</td>\n",
              "      <td>0.609883</td>\n",
              "      <td>0.008432</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.481838</td>\n",
              "      <td>0.006536</td>\n",
              "      <td>0.138249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.732799</td>\n",
              "      <td>0.761855</td>\n",
              "      <td>0.607133</td>\n",
              "      <td>0.488781</td>\n",
              "      <td>0.432008</td>\n",
              "      <td>0.410256</td>\n",
              "      <td>0.511364</td>\n",
              "      <td>0.402568</td>\n",
              "      <td>0.455657</td>\n",
              "      <td>...</td>\n",
              "      <td>0.321463</td>\n",
              "      <td>0.456123</td>\n",
              "      <td>0.562226</td>\n",
              "      <td>0.466533</td>\n",
              "      <td>0.629812</td>\n",
              "      <td>0.008432</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477218</td>\n",
              "      <td>0.006536</td>\n",
              "      <td>0.115207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.732938</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>0.606895</td>\n",
              "      <td>0.488791</td>\n",
              "      <td>0.418858</td>\n",
              "      <td>0.407724</td>\n",
              "      <td>0.488636</td>\n",
              "      <td>0.396526</td>\n",
              "      <td>0.456104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.347219</td>\n",
              "      <td>0.456692</td>\n",
              "      <td>0.572002</td>\n",
              "      <td>0.487845</td>\n",
              "      <td>0.643598</td>\n",
              "      <td>0.006745</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.492623</td>\n",
              "      <td>0.008715</td>\n",
              "      <td>0.092166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.732893</td>\n",
              "      <td>0.761656</td>\n",
              "      <td>0.606478</td>\n",
              "      <td>0.488802</td>\n",
              "      <td>0.417896</td>\n",
              "      <td>0.404242</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.405589</td>\n",
              "      <td>0.460020</td>\n",
              "      <td>...</td>\n",
              "      <td>0.361904</td>\n",
              "      <td>0.460532</td>\n",
              "      <td>0.563354</td>\n",
              "      <td>0.479512</td>\n",
              "      <td>0.644690</td>\n",
              "      <td>0.008432</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.457064</td>\n",
              "      <td>0.008715</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.732788</td>\n",
              "      <td>0.761573</td>\n",
              "      <td>0.606777</td>\n",
              "      <td>0.488800</td>\n",
              "      <td>0.421103</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.511364</td>\n",
              "      <td>0.399547</td>\n",
              "      <td>0.458507</td>\n",
              "      <td>...</td>\n",
              "      <td>0.359767</td>\n",
              "      <td>0.458825</td>\n",
              "      <td>0.563354</td>\n",
              "      <td>0.448298</td>\n",
              "      <td>0.629948</td>\n",
              "      <td>0.006745</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.472223</td>\n",
              "      <td>0.006536</td>\n",
              "      <td>0.170507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.732654</td>\n",
              "      <td>0.761304</td>\n",
              "      <td>0.607815</td>\n",
              "      <td>0.488751</td>\n",
              "      <td>0.403143</td>\n",
              "      <td>0.402026</td>\n",
              "      <td>0.528409</td>\n",
              "      <td>0.383686</td>\n",
              "      <td>0.449682</td>\n",
              "      <td>...</td>\n",
              "      <td>0.357345</td>\n",
              "      <td>0.450149</td>\n",
              "      <td>0.577767</td>\n",
              "      <td>0.462758</td>\n",
              "      <td>0.626945</td>\n",
              "      <td>0.006745</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.475962</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>0.138249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.732544</td>\n",
              "      <td>0.761418</td>\n",
              "      <td>0.607595</td>\n",
              "      <td>0.488748</td>\n",
              "      <td>0.425914</td>\n",
              "      <td>0.408357</td>\n",
              "      <td>0.528409</td>\n",
              "      <td>0.419562</td>\n",
              "      <td>0.453380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.364608</td>\n",
              "      <td>0.453705</td>\n",
              "      <td>0.566612</td>\n",
              "      <td>0.475290</td>\n",
              "      <td>0.629402</td>\n",
              "      <td>0.006745</td>\n",
              "      <td>0.003559</td>\n",
              "      <td>0.487324</td>\n",
              "      <td>0.008715</td>\n",
              "      <td>0.129032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.732575</td>\n",
              "      <td>0.761475</td>\n",
              "      <td>0.608642</td>\n",
              "      <td>0.488771</td>\n",
              "      <td>0.428480</td>\n",
              "      <td>0.415321</td>\n",
              "      <td>0.534091</td>\n",
              "      <td>0.411254</td>\n",
              "      <td>0.464791</td>\n",
              "      <td>...</td>\n",
              "      <td>0.307913</td>\n",
              "      <td>0.465083</td>\n",
              "      <td>0.567239</td>\n",
              "      <td>0.488204</td>\n",
              "      <td>0.631313</td>\n",
              "      <td>0.008432</td>\n",
              "      <td>0.003559</td>\n",
              "      <td>0.473797</td>\n",
              "      <td>0.010893</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.732440</td>\n",
              "      <td>0.761603</td>\n",
              "      <td>0.608882</td>\n",
              "      <td>0.488807</td>\n",
              "      <td>0.427518</td>\n",
              "      <td>0.410890</td>\n",
              "      <td>0.517045</td>\n",
              "      <td>0.407100</td>\n",
              "      <td>0.464057</td>\n",
              "      <td>...</td>\n",
              "      <td>0.309998</td>\n",
              "      <td>0.464514</td>\n",
              "      <td>0.576889</td>\n",
              "      <td>0.493189</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.008432</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.481318</td>\n",
              "      <td>0.008715</td>\n",
              "      <td>0.147465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.732574</td>\n",
              "      <td>0.761135</td>\n",
              "      <td>0.609090</td>\n",
              "      <td>0.488796</td>\n",
              "      <td>0.418217</td>\n",
              "      <td>0.414688</td>\n",
              "      <td>0.528409</td>\n",
              "      <td>0.402190</td>\n",
              "      <td>0.457764</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318445</td>\n",
              "      <td>0.458256</td>\n",
              "      <td>0.574759</td>\n",
              "      <td>0.502262</td>\n",
              "      <td>0.627628</td>\n",
              "      <td>0.008432</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.483109</td>\n",
              "      <td>0.006536</td>\n",
              "      <td>0.124424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e9821dd-fca2-4ae4-8a55-01bc6e1a2473')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e9821dd-fca2-4ae4-8a55-01bc6e1a2473 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e9821dd-fca2-4ae4-8a55-01bc6e1a2473');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29ed00aa-9116-4e73-88b9-512ea98582d8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29ed00aa-9116-4e73-88b9-512ea98582d8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29ed00aa-9116-4e73-88b9-512ea98582d8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJAfAJVOKcpo",
        "outputId": "51507b85-f817-4e69-a195-2f20e3847979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train data: (132481, 26)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of train data:\", df_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ioGUt5EKcpo",
        "outputId": "ebcc08b9-aa21-47b8-b3fc-7d1b55ca3874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Noise Mask: (132481, 26)\n"
          ]
        }
      ],
      "source": [
        "def generate_binary_noise_mask(num_samples, num_features, masked_proportion, mean_length):\n",
        "    pm_to_m = 1 - 1 / mean_length\n",
        "    pm_to_u = 1 / mean_length\n",
        "    pu_to_m = (1 / mean_length) * (masked_proportion / (1 - masked_proportion))\n",
        "    pu_to_u = 1 - (1 / mean_length) * (masked_proportion / (1 - masked_proportion))\n",
        "\n",
        "    P = np.array([[pm_to_m, pm_to_u],\n",
        "                  [pu_to_m, pu_to_u]])\n",
        "    M = np.zeros((num_samples, num_features), dtype=int)\n",
        "    state = np.random.choice([0, 1], size=num_samples)\n",
        "    for i in range(1, num_samples):\n",
        "        state[i] = np.random.choice([0, 1], p=P[state[i-1]])\n",
        "    mask_lengths = np.random.geometric(p=1/mean_length, size=num_samples)\n",
        "    for i, length in enumerate(mask_lengths):\n",
        "        start_idx = np.random.randint(0, num_features - length + 1)\n",
        "        end_idx = start_idx + length\n",
        "        M[i, start_idx:end_idx] = 1\n",
        "\n",
        "    return M\n",
        "\n",
        "no_samples = len(df_train)\n",
        "no_features = len(df_train.columns) - 1 # Ignore time stamp column\n",
        "masked_proportion = 0.2\n",
        "mean_length = 2\n",
        "\n",
        "binary_noise_mask = generate_binary_noise_mask(no_samples, no_features, masked_proportion, mean_length)\n",
        "print(\"Binary Noise Mask:\", df_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, num_heads, d_model, dff, input_data_shape):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        self.dff = dff\n",
        "        self.input_data_shape = input_data_shape\n",
        "        self.embedding = layers.Dense(d_model)\n",
        "        self.pos_encoding = self.positional_encoding()\n",
        "        self.enc_layers = [self.create_encoder_layer() for _ in range(2)]\n",
        "\n",
        "    def create_encoder_layer(self):\n",
        "        return layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.d_model // self.num_heads)\n",
        "\n",
        "    def positional_encoding(self):\n",
        "        position = tf.range(self.input_data_shape[1], dtype=tf.float32)[:, tf.newaxis]\n",
        "        angle_rads = 1 / tf.pow(10000, (2 * (tf.range(self.d_model, dtype=tf.float32) // 2)) / tf.cast(self.d_model, tf.float32))\n",
        "        angle_rads = tf.reshape(angle_rads, (1, -1))  # Reshape to broadcast across positions\n",
        "\n",
        "        # Compute sin and cos values for even and odd indices\n",
        "        sin_indices = tf.math.sin(position * angle_rads[:, 0::2])\n",
        "        cos_indices = tf.math.cos(position * angle_rads[:, 1::2])\n",
        "\n",
        "        # Interleave sin and cos values\n",
        "        pos_encoding = tf.stack([sin_indices, cos_indices], axis=2)\n",
        "        pos_encoding = tf.reshape(pos_encoding, (1, -1, self.d_model))\n",
        "        return pos_encoding\n",
        "\n",
        "\n",
        "class Generator(Model):\n",
        "    def __init__(self, num_heads, d_model, dff, input_data_shape, output_shape):\n",
        "        super(Generator, self).__init__()\n",
        "        self.input_data_shape = input_data_shape\n",
        "        self.encoder = TransformerEncoder(num_heads, d_model, dff, input_data_shape)\n",
        "\n",
        "    def call(self, inputs, binary_noise_mask):\n",
        "        # Encode the input data using the Transformer-based encoder with binary noise mask\n",
        "        encoded_data = self.encoder(inputs, binary_noise_mask)\n",
        "        return encoded_data\n",
        "\n",
        "# Define model parameters\n",
        "num_heads = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "masked_proportion = 0.2\n",
        "\n",
        "# Get input shape from df_train\n",
        "input_shape = df_train.shape\n",
        "\n",
        "# Instantiate the Generator model\n",
        "generator = Generator(num_heads, d_model, dff, input_shape, input_shape)\n",
        "\n",
        "# Encode the input data using the generator\n",
        "encoded_data = generator(df_train.values, binary_noise_mask)\n",
        "print(encoded_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpyvakNSR-As",
        "outputId": "c89a8e77-d7bd-44ce-a883-c0a83f49b956"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.00000000e+00 7.32689381e-01 7.61747539e-01 ... 4.81838137e-01\n",
            "  6.53594779e-03 1.38248846e-01]\n",
            " [1.00000000e+00 7.32798815e-01 7.61854529e-01 ... 4.77218270e-01\n",
            "  6.53594779e-03 1.15207374e-01]\n",
            " [2.00000000e+00 7.32937992e-01 7.61593759e-01 ... 4.92622644e-01\n",
            "  8.71459674e-03 9.21659023e-02]\n",
            " ...\n",
            " [1.32478000e+05 7.75366724e-01 9.09095883e-01 ... 1.52412444e-01\n",
            "  8.71459674e-03 1.19815670e-01]\n",
            " [1.32479000e+05 7.75383413e-01 9.09189463e-01 ... 1.53408602e-01\n",
            "  8.71459674e-03 1.01382487e-01]\n",
            " [1.32480000e+05 7.75373936e-01 9.09185112e-01 ... 1.73375100e-01\n",
            "  8.71459674e-03 1.05990782e-01]], shape=(132481, 26), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check if GPU is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_data(file_path):\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(file_path)\n",
        "    # Assuming the time series data doesn't need to handle timestamps for model input\n",
        "    features = data.drop(['timestamp_(min)'], axis=1, errors='ignore')  # drop non-feature columns\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    tensor_data = torch.tensor(scaled_features, dtype=torch.float32)\n",
        "    return tensor_data\n",
        "\n",
        "# Load and preprocess data\n",
        "data_tensor = load_data(train_file_path)\n",
        "\n",
        "# Create a DataLoader\n",
        "train_loader = DataLoader(data_tensor, batch_size=64, shuffle=True)\n",
        "\n",
        "def generate_binary_noise_mask(num_samples, num_features, masked_proportion, mean_length):\n",
        "    # Calculate transition probabilities\n",
        "    pm_to_u = 1 / mean_length  # Mask to unmask\n",
        "    pm_to_m = 1 - pm_to_u      # Mask to mask\n",
        "    pu_to_m = pm_to_u * (masked_proportion / (1 - masked_proportion))  # Unmask to mask\n",
        "    pu_to_u = 1 - pu_to_m      # Unmask to unmask\n",
        "\n",
        "    # Generate binary noise mask matrix using Markov chain for each feature\n",
        "    mask = np.zeros((num_samples, num_features), dtype=int)\n",
        "\n",
        "    for feature in range(num_features):\n",
        "        # Start unmasked\n",
        "        state = np.random.choice([0, 1], p=[1 - masked_proportion, masked_proportion])\n",
        "        mask[0, feature] = state\n",
        "\n",
        "        for i in range(1, num_samples):\n",
        "            if state == 1:  # If currently masked\n",
        "                state = np.random.choice([0, 1], p=[pm_to_u, pm_to_m])\n",
        "            else:  # If currently unmasked\n",
        "                state = np.random.choice([0, 1], p=[pu_to_m, pu_to_u])\n",
        "            mask[i, feature] = state\n",
        "\n",
        "    return torch.tensor(mask, dtype=torch.float32)\n",
        "\n",
        "def masked_dataloader(data_tensor, batch_size, masked_proportion, mean_length):\n",
        "    # Generate masks for all data\n",
        "    num_samples, num_features = data_tensor.size()\n",
        "    mask = generate_binary_noise_mask(num_samples, num_features, masked_proportion, mean_length)\n",
        "    masked_data = data_tensor * mask  # Element-wise multiplication to apply the mask\n",
        "\n",
        "    # Create a DataLoader\n",
        "    dataset = TensorDataset(masked_data, data_tensor)  # Using original data as target\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Example usage\n",
        "train_loader = masked_dataloader(data_tensor, batch_size=64, masked_proportion=0.2, mean_length=5)\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, feature_size, num_heads, num_layers, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.encoder_layers = nn.TransformerEncoderLayer(d_model=feature_size, nhead=num_heads, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layers, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, src):\n",
        "        return self.transformer_encoder(src)\n",
        "\n",
        "class MLPDecoder(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLPDecoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
        "        self.fc2 = nn.Linear(output_dim, output_dim)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        return self.activation(self.fc2(x))\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, feature_size, num_heads, num_encoder_layers, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.encoder = TransformerEncoder(feature_size, num_heads, num_encoder_layers)\n",
        "        self.decoder = MLPDecoder(feature_size, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        reconstructed = self.decoder(latent)\n",
        "        return reconstructed\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        return self.activation(self.fc2(x))\n",
        "\n",
        "# Reconstruction Loss\n",
        "def reconstruction_loss(reconstructed, original):\n",
        "    return nn.functional.mse_loss(reconstructed, original)\n",
        "\n",
        "# Set up models, optimizers\n",
        "generator = Generator(feature_size=25, num_heads=5, num_encoder_layers=3, output_dim=25).to(device)\n",
        "discriminator = Discriminator(input_dim=25).to(device)\n",
        "\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.001)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "\n",
        "def train_epoch(generator, discriminator, loader, g_optimizer, d_optimizer, device):\n",
        "    for masked_data, real_data in loader:\n",
        "        masked_data, real_data = masked_data.to(device), real_data.to(device)\n",
        "\n",
        "        # Forward pass through generator\n",
        "        generated_data = generator(masked_data)\n",
        "\n",
        "        # Discriminator training\n",
        "        d_optimizer.zero_grad()\n",
        "        real_pred = discriminator(real_data)\n",
        "        fake_pred = discriminator(generated_data.detach())\n",
        "        d_loss = -(torch.log(real_pred) + torch.log(1 - fake_pred)).mean()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Generator training\n",
        "        g_optimizer.zero_grad()\n",
        "        fake_pred = discriminator(generated_data)\n",
        "        g_loss = -torch.log(fake_pred).mean()\n",
        "        rec_loss = nn.functional.mse_loss(generated_data, real_data)  # Reconstruction loss\n",
        "        total_g_loss = g_loss + rec_loss\n",
        "        total_g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "# Driver Code\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    train_epoch(generator, discriminator, train_loader, g_optimizer, d_optimizer, device)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs} completed.')\n",
        "\n",
        "print(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK5g7GzfdXDs",
        "outputId": "562080c8-890c-429c-a0eb-db9dc9364e14"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 completed.\n",
            "Epoch 2/2 completed.\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7bcb3f6f0f10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_anomalies(data_loader, generator, threshold, device):\n",
        "    anomalies = []\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, _ in data_loader:\n",
        "            data = data.to(device)\n",
        "            reconstructed_data = generator(data)\n",
        "            error = nn.functional.mse_loss(reconstructed_data, data, reduction='none')\n",
        "            error = error.mean(dim=1)\n",
        "            anomalies.extend((error > threshold).cpu().numpy())\n",
        "\n",
        "    return anomalies\n",
        "\n",
        "# Example usage for detecting anomalies\n",
        "threshold = 0.5\n",
        "anomalies_detected = calculate_anomalies(train_loader, generator, threshold, device)\n",
        "print(f\"Count of anomalies: {np.sum(anomalies_detected)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMcKCsnbjbVM",
        "outputId": "7beede6d-1696-441c-f7bb-5af199e3e1cf"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of anomalies: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, Model\n",
        "\n",
        "# # Data Augmentation Module\n",
        "# class DataAugmentation:\n",
        "#     def __init__(self, masked_proportion=0.2, mean_length=2):\n",
        "#         self.masked_proportion = masked_proportion\n",
        "#         self.mean_length = mean_length\n",
        "\n",
        "#     def generate_binary_noise_mask(self, num_samples, num_features):\n",
        "#         pm_to_m = 1 - 1 / self.mean_length\n",
        "#         pm_to_u = 1 / self.mean_length\n",
        "#         pu_to_m = (1 / self.mean_length) * (self.masked_proportion / (1 - self.masked_proportion))\n",
        "#         pu_to_u = 1 - (1 / self.mean_length) * (self.masked_proportion / (1 - self.masked_proportion))\n",
        "\n",
        "#         P = np.array([[pm_to_m, pm_to_u],\n",
        "#                       [pu_to_m, pu_to_u]])\n",
        "#         M = np.zeros((num_samples, num_features), dtype=int)\n",
        "#         state = np.random.choice([0, 1], size=num_samples)\n",
        "#         for i in range(1, num_samples):\n",
        "#             state[i] = np.random.choice([0, 1], p=P[state[i-1]])\n",
        "#         mask_lengths = np.random.geometric(p=1/self.mean_length, size=num_samples)\n",
        "#         for i, length in enumerate(mask_lengths):\n",
        "#             start_idx = np.random.randint(0, num_features - length + 1)\n",
        "#             end_idx = start_idx + length\n",
        "#             M[i, start_idx:end_idx] = 1\n",
        "\n",
        "#         return M\n",
        "\n",
        "# # Generator Module\n",
        "# class TransformerEncoder(layers.Layer):\n",
        "#     def __init__(self, num_heads, d_model, dff, input_size):\n",
        "#         super(TransformerEncoder, self).__init__()\n",
        "#         self.num_heads = num_heads\n",
        "#         self.d_model = d_model\n",
        "#         self.dff = dff\n",
        "#         self.input_size = input_size\n",
        "#         self.embedding = layers.Dense(d_model)\n",
        "#         self.pos_encoding = self.positional_encoding()\n",
        "#         self.enc_layers = [self.create_encoder_layer() for _ in range(2)]\n",
        "\n",
        "#     def create_encoder_layer(self):\n",
        "#         return layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.d_model // self.num_heads)\n",
        "\n",
        "#     def positional_encoding(self):\n",
        "#         position = tf.range(self.input_size[1], dtype=tf.float32)[:, tf.newaxis]\n",
        "#         angle_rads = 1 / tf.pow(10000, (2 * (tf.range(self.d_model, dtype=tf.float32) // 2)) / tf.cast(self.d_model, tf.float32))\n",
        "#         pos_encoding = position * angle_rads\n",
        "#         pos_encoding[:, 0::2] = tf.sin(pos_encoding[:, 0::2])\n",
        "#         pos_encoding[:, 1::2] = tf.cos(pos_encoding[:, 1::2])\n",
        "#         pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "#         return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "#     def call(self, inputs, binary_noise_mask):\n",
        "#         x = self.embedding(inputs)\n",
        "#         x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "#         x += self.pos_encoding[:, :tf.shape(x)[1], :]\n",
        "\n",
        "#         # Apply binary noise mask element-wise\n",
        "#         masked_x = tf.subtract(x, tf.multiply(x, binary_noise_mask))\n",
        "\n",
        "#         for enc_layer in self.enc_layers:\n",
        "#             masked_x = enc_layer(masked_x, masked_x)\n",
        "#         return masked_x\n",
        "\n",
        "# class Generator(Model):\n",
        "#     def __init__(self, num_heads, d_model, dff, input_size):\n",
        "#         super(Generator, self).__init__()\n",
        "#         self.encoder = TransformerEncoder(num_heads, d_model, dff, input_size)\n",
        "\n",
        "#     def call(self, inputs, binary_noise_mask):\n",
        "#         # Encode the input data using the Transformer-based encoder with binary noise mask\n",
        "#         encoded_data = self.encoder(inputs, binary_noise_mask)\n",
        "#         return encoded_data\n",
        "\n",
        "# # Discriminator Module\n",
        "# class Discriminator(Model):\n",
        "#     def __init__(self, input_size):\n",
        "#         super(Discriminator, self).__init__()\n",
        "#         self.flatten = layers.Flatten()\n",
        "#         self.dense_1 = layers.Dense(64, activation='relu')\n",
        "#         self.dense_2 = layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         x = self.flatten(inputs)\n",
        "#         x = self.dense_1(x)\n",
        "#         return self.dense_2(x)\n",
        "\n",
        "# # Contrastive Learning Module\n",
        "# class ContrastiveLoss(tf.keras.losses.Loss):\n",
        "#     def __init__(self, temperature=1.0):\n",
        "#         super(ContrastiveLoss, self).__init__()\n",
        "#         self.temperature = temperature\n",
        "\n",
        "#     def call(self, positive_pairs, negative_pairs):\n",
        "#         cosine_similarity = tf.reduce_sum(tf.multiply(positive_pairs, negative_pairs), axis=-1)\n",
        "#         softmax_scores = tf.nn.softmax(cosine_similarity / self.temperature, axis=-1)\n",
        "#         loss = -tf.math.log(softmax_scores[:, 0])\n",
        "#         return tf.reduce_mean(loss)\n",
        "\n",
        "# num_samples, num_features = df_train.shape\n",
        "# num_heads = 4\n",
        "# d_model = 128\n",
        "# dff = 512\n",
        "# input_size = (num_samples, num_features)\n",
        "\n",
        "# # Instantiate modules\n",
        "# data_augmentation = DataAugmentation()\n",
        "# generator = Generator(num_heads=num_heads, d_model=d_model, dff=dff, input_size=input_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "Sd929EwcSCjP",
        "outputId": "2c52a95b-8b51-420c-ceb4-083bdd6fde97"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-222ec9ca2145>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# Instantiate modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0mdata_augmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataAugmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-222ec9ca2145>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_heads, d_model, dff, input_size)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_noise_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-222ec9ca2145>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_heads, d_model, dff, input_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_encoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-222ec9ca2145>\u001b[0m in \u001b[0;36mpositional_encoding\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mangle_rads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mpos_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mangle_rads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mpos_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mpos_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mpos_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}